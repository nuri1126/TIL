## 빅데이터
### 빅데이터 개념 및 3요소
- 기존 데이터베이스 관리도구의 데이터 수집, 저장, 관리, 분석하는 역량을 넘어서는 데이터 
  ⇒ 규모에 초점
- 다양한 종류의 대규모 데이터로부터 저렴한 비용으로 가치를 추출하고, 데이터의 빠른 수집, 발굴/분석을 지원하도록 고안된 차세대 아키텍처 
  ⇒ 업무 수행 방식에 초점 

### 빅데이터 개념 및 3요소
1. volume(크기) : 소위 말해 TB, PB 그 이상에 해당되는 데이터 
  - 관점은 조직에 따라 다름, 상대적일 수 있다.
  - data warehouse에서도 처리 불가한 데이터를 분산 컴퓨팅 솔루션으로 해결 (구글 GFS, 하둡 등)
2. velocity(속도) : 실시간처리 방법, 장기적 관점의 접근 방법 등
  - 실시간 데이터 형태 : 교통정보, 금융, 서핑 history → 매 순간 순간 많은 데이터가 생성 됨
  - 장기적 관점 : 대량의 데이터를 다양한 분석, 시각화 기법으로 표현해내는 것 
3. variety(다양성) : 데이터(정형, 반정형, 비정형 데이터)
  - 정형 : 형식이 정해짐 (이름, 전화, 주소 ...)
  - 비정형 : 위와 같지 않은 구분되지않은 막섞여있는, 고정된 필드에 있지 않은 data
      (사진, 음성, 위치정보, 통화내용 등)
  - 반정형 : XML, HTML 등의 스키마로 표현되는 데이터
  <u>세 가지중 두가지 이상이 충족되는 것을 빅데이터라고 한다.</u>
## 하둡(Hadoop)
- 대용량 데이터를 분산처리할 수 있는 자바 기반의 오픈소스 프레임워크 (리눅스 기반이라면 문제없이 작동 됨)
- 분산파일시스템(HDFS)과 분산처리 시스템인 맵리듀스로 구성

### 하둡 에코시스템(=하둡의 생태계)
<img src="https://lh6.googleusercontent.com/dge7EwAJOla2dMKcEVgVNKb9pX2XRQMlU_f7rCKrWw_BAJ1cTjwoqQaVJdsJJq9G8Yxc7ZkBwP7d9rFAIQV2Dm59vAILvj3Wd55004-wsKJxamFNSB9Ka0i-8q8r3gGkEcuPCvC4">

- 비지니스에 적용시키기 위해서는 그에 맞는 기능을 제공해야함
#### 코어기능 : 분산 데이터 저장, 분산 데이터 배치 처리, 분산 클러스터 리소스 관리
#### 분산코디네이터(주키퍼) : 분산 서버들과 상호작용하는 역할
- 말 그대로 하나의 서버에 서비스가 집중되지 않도록 분산하여 동시처리가 가능하도록 함
- 하나의 서버에서 처리한 결과를 다른서버와 동기화하여 데이터 안정성 유지
- 운영서버에서 문제 발생시 대기중인 서버가 있다면 대기중인 서버가 있을 시 그 서버를 운영서버로 바꿔서 서비스가 중지 되지 않도록 함
- 분산환경을 구성하는 서버의 통합 환경설정
#### 리소스 관리
##### YARN 
- 데이터 처리작업을 실행하기 위한 클러스터 자원들 or 스케줄링을 하기위한 프레임워크
- mapreduce의 단점을 극복하기 위해 만들어짐
   자원을 잘 사용할 수 있도록…
- 하이브, 임팔라, 타조, 스파크 등은 얀을 통해 리소스를 할당받아 작업 수행

참고 - Mesos : 클라우드 인프라 스트럭쳐, 컴퓨터 엔진 자원을 의미 
자원관리 프로젝트 중 하나
아파치의 최상위 프로젝트로 진행 중이라고 함
facebook, twitter, ebay 등이 mesos로 클러스터자원을 관리하는 중

- 클러스터란 : 목적을 가지고 수행되는 컴퓨터들의 집합

#### 분산 데이터베이스(HBASE)
- HDFS기반, column기반, 피드기반, 열기반 데이터베이스
- 실시간으로 랜덤조회 가능, 실시간 업데이트 가능 
- 각 프로세스들은 개인의 데이터를 비동기적으로 업데이트 가능
- 맵리듀스는 일괄처리 방식으로 처리됨, 트위터, 야후 …
- 네이버가 모바일 메신저에 hbase를 적용한 발표를 한 적이 있음

#### 컬럼 기반 스토리지(KUDU)
- 특정 culumn에 대한 데이터를 아주 빠르게 처리할 수 있음
- 기존에도 HDFS에서 데이터 저장이 가능한데 자체적으로는 적합하지 않았는데, KUDU는 HBASE에서의 이러한 속도가 느리다는 단점을 보완해서 개발한 컬럼기반 스토리지
- 데이터 발생부터 분석까지 시간 단축 가능
- 아파치 인큐베이션 프로젝트로 선정됨

#### 데이터 수집
##### 스트리밍 데이터 수집
- chuckwa : 분산환경에서 생성되는 데이터를 HDFS에 안정적으로 저장될 수 있도록, 에이전트로부터 데이터를 받아서 콜렉터가 필요한 데이터를 수집하면 HDFS에 저장하게 되는데 100개의 에이전트당 콜렉터 한개, 데이터 중복 같은 것들은 맵리듀스로 해결 
- Fluma: 분산된 서버에 에이전트 설치를 해놓고 그로부터 데이터를 전달받음, 전체데이터관리를 하는 마스터서버가 있기 때문에 동적으로 변경 가능
- Scribe : 페이스북의 데이터 수집 플랫폼, 1과다르게 데이터를 중앙집중 서버로 보냄, 쉬움
##### DBMS 데이터 수집
- Sqoop: 대용량 데이터 전송을 해주는 솔루션 중 하나, 아파치 최상위 프로젝트, 다양한 저장소에 대용량 데이터를 신속히 저장
- Hiho : 대용량 데이터 전송 솔루션, 

#### 분산 메세지 처리
- Kafka : 데이터 스트림을 실시간으로 관리하기 위한 분산 메세징 시스템, 대용량 이벤트 처리를 위해 링크드인에서 개발함, 발행, 구독, 모델로 구성, 데이터 손실을 막기 위해 디스크에 데이터 저장, 파티셔닝이 지원되어 다수의 kafka서버에서 분산처리 가능, 로드밸런싱 , 내구장성 보장, 다수의 글로버 기업들이 사용함, 하루에 엄청난 메세지를 처리하고 있음

#### 데이터 처리
- pig : 아파치 프로그램에 있음 복잡한 맵리듀스를 대체할 수단 제공, 단순한 형태,sql과 같은 유사형태로 설계됨
- mahout : 하둡 기반 데이터 마이닝 알고리즘 부여한 오픈소스, 어플리케이션 분류, 클러스터링, 협업 필터, 회귀분석 등의 알고리즘 제공해줌, 그대로 사용하거나 최적화해서 사용 가능
- spark : 아주 중요해요, 인메모리 기반의 범용 데이터 처리 플랫폼, 실시간 데이터 처리, 그래프 라이브러리 처리 등 ,,, 버클리에서 시작됨,최근에 상당한 인기임
- impala : 하둡 기반의 분산 처리 엔진, 맵리듀스 아닌 c++로 개발한 인메모리 엔진 사용해서 빠름, 데이터 조회를 위한 인터페이스로 hive ql사용, sql질의결과를 아주빨리 확인 가능, 쿼리엔
- presto : 페이스북의 대화형 질의를 처리하기 위한 분산 쿼리 엔진, 메모리기반 데이터 처리, 다양한 저장소의 데이터를 sql 처리 가능, 하이브에 비해 열배정도 빠른 성능
- hive : 페이스북에서 개발, 오픈소스, sql과 유사한 쿼리 언어 제공, java를 몰라도 쉽게 분석할 수 있음, hiveql은 내부적으로 맵리듀스잡으로 변환되어서 활용됨
- tajo : 하둡기반의 데이터 웨어 하우스, 고려대 개발, 맵리듀스가 아닌 자체 분산 처리 엔진 사용, hive사용하는 다른시스템과는 달리 표준 sql지원, 질의유형에 따라 다른 것보다 빠른 성능 보여줌

#### 워크플로우 : 하둡 작업을 관리하는 시스템     

#### 데이터 시각화 : 발 그대로 분석결과를 즉시 시각화 해서 제공해줌, 다양한 분석 플랫폼과 연동 가능

#### 데이터 직렬화 : 
- Avro: 작고 빠른 바이너리 포멧으로 정렬해줌
- thrift: 다양한 언어로 개발된 것들을 모듈들로 통합해서 제공

